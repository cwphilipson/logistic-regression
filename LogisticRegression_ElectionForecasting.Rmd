---
title: "Logistic Regression - Election Forecasting"
author: "Casandra Philipson"
date: "February 26, 2016"
output: html_document
---

##Overview: Polling and Election Prediction
_Predicting the winner before any votes are cast_

This analysis will assess tries to predict the state winner of a presidential election based on 3 election years. Recall that electoral votes, which are distributed based on population, determine winnings. This means the population vote doesn't guarentee presidential election.  

Use polling data to predict state winners. The data is from RealClearPolitics.com.  

###Dealing with Missing Data
```{r}
polling = read.csv("PollingData.csv")
str(polling)
table(polling$Year)

#Look at how many NAs exist
summary(polling)
```
There are quite a few missing datapoints due to different polling in different states over the years.  
  
__Approaches for Missing Data__  
__1__. Delete missing observations (throw away 50% of data)  
__2__. Delete variables with missing values  
__3__. Fill missing data points with average values (not best)  
__4__. Multiple Imputation (fill in missing values based on non-missing values) **best option**  

```{r}
# MULTIPLE IMPUTATION
suppressMessages(library(mice))

# Obtain desired data
simple <- polling[c("Rasmussen", "SurveyUSA", "PropR", "DiffCount")]

# Set seed for reproducibility
set.seed(144)

#Fill in missing data points & replace in polling data frame
imputed <- complete(mice(simple))
summary(imputed)
polling$Rasmussen <- imputed$Rasmussen
polling$SurveyUSA<- imputed$SurveyUSA
summary(polling)
```

###A Sophisticated Baseline Model
__Subset training versus testing data sets__
```{r}
Train <- subset(polling, Year == 2004 | Year == 2008)
Test <- subset(polling, Year == 2012)

# Smart Baseline using sign function
table(sign(Train$Rasmussen))
```
The __sign()__ function takes any positive value and returns 1, any negative value and return -1, and return 0 with 0. 

```{r}
# Compare outcome to polled data
table(Train$Republican, sign(Train$Rasmussen))
```
When comparing the predictions to actual outcome, the model successfully predicts 42 times Democrat, and 52 times Republican. There are 3 instances in which the model predicts Democrat where the outcome was actually Republican.    
__This model is a good baseline model to compare future linear regression models to.__
  
  
### Logistic Regression Model
__1__. Looking for coorleation and multicollinearity  
```{r}
cor(Train[c("Rasmussen", "SurveyUSA", "PropR", "DiffCount", "Republican")])
```
We are interested in a variable is most correlated to Republican, so PropR.

__2__. Build a model with important features
```{r}
# 1-variable Logistic Regression Model
mod1 <- glm(Republican~PropR, data=Train, family = "binomial")
summary(mod1)

# Training set predictions
pred1 <- predict(mod1, type="response")
table(Train$Republican, pred1 >= 0.5)
```
Results indicate that the 1-variable model performs very similar to the baseline model. Therefore, we want to improve our model by adding another variale. Look back at the coorelation results and identify two variables that are minimally coorelated but have a positive influence on Republican outcome.  
__3__. Build a multi-variable model to imprive prediction based on two features with low multicollinearity.
```{r}
# Two-variable model
mod2 <- glm(Republican~SurveyUSA+DiffCount, data = Train, family = "binomial")
pred2 <- predict(mod2, type = "response")
table(Train$Republican, pred2 >= 0.5)
summary(mod2)
```
Still nothing too impressive... neither variable have a significant impact on the mode. Nevertheless, we will use the two-variable model to make predictions on the test set. 

### Test Set Predictions
```{r}
# Smart baseline accuracy
table(Test$Republican, sign(Test$Rasmussen))

# Test set predictions
TestPrediction <- predict(mod2, newdata = Test, type = "response")
table(Test$Republican, TestPrediction >= 0.5)

# Analyze mistake
subset(Test, TestPrediction >= 0.5 & Republican == 0)

```

### Conclusions
We created a sophisticated baseline model along with a multi-variable logistic regression model to forcast Presidential election winnings.  
  
The multi-variable model worked best. All but 1 guesses were correct. Our mistake was on Florida since the all predictions suggested that the Republican would win however surprisingly, the Democratic cantidate took the win.
